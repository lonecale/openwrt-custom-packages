name: Sync OpenWrt fix

on:
  schedule:
    - cron: "20 5 * * *"  # 每天13点触发此工作流
  workflow_dispatch:  # 允许手动触发工作流

jobs:
  cleanup:
    runs-on: ubuntu-24.04
    env:
      TZ: 'Asia/Shanghai'

    # strategy:
      # matrix:
        # repo: ["openwrt/openwrt","openwrt/packages", "openwrt/luci", "openwrt/telephony", "openwrt/routing"]  # 多仓库支持

    steps:
    # 克隆仓库并处理
    - name: Checkout repository
      uses: actions/checkout@main
      # 使用actions/checkout来获取工作目录

    # 设置 GitHub Token
    - name: Set up GitHub token
      run: echo "GITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}" >> $GITHUB_ENV

    # 定义关键词（在此步骤中设置KEYWORD）
    - name: Define keyword
      run: |
        echo "KEYWORD=fix+GCC14" >> $GITHUB_ENV

    # 克隆仓库并处理每个仓库
    - name: Process repositories
      run: |
        #!/bin/bash
        # REPO=${{ matrix.repo }}
        GITHUB_TOKEN="${{ secrets.GITHUB_TOKEN }}"
        KEYWORD="${{ env.KEYWORD }}"
        REPOS=("openwrt/openwrt" "openwrt/packages" "openwrt/luci" "openwrt/routing" "openwrt/telephony")
        for REPO in "${REPOS[@]}"; do
        # 提取仓库名称和目录
          REPO_NAME=$(echo "$REPO" | cut -d'/' -f2)
          REPO_DIR="openwrt_tmp/$REPO_NAME"
          mkdir -p "$REPO_DIR"
          # 克隆仓库
          echo -e "\033[34m正在克隆仓库: $REPO\033[0m"
          git clone "https://github.com/$REPO.git" "$REPO_DIR"
          
          REPO_RESULTS=()  # 用于存储该仓库的所有公共目录路径

          # 初始化该仓库的提交列表
          REPO_COMMIT_LIST=""
          # 页数变量初始化
          PAGE=1
          PER_PAGE=100  # 每页返回的提交数

          # 定义存储已处理提交链接的文件路径
          PROCESSED_COMMITS_FILE="./$REPO/processed_commits.txt"
          DIRECTORY_FILE="./$REPO/directory_list.txt"
          COMMIT_URLS=""

          # 获取包含指定关键词的提交记录
          while :; do
            # 获取包含 "GCC14" 的提交
            # RESPONSE=$(curl -s -H "Authorization: token $GITHUB_TOKEN" "https://api.github.com/search/commits?q=repo:$REPO+$KEYWORD&per_page=$PER_PAGE&page=$PAGE&sort=committer-date&order=desc" -H "Accept: application/vnd.github.v3.full+json")
            RESPONSE=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
              "https://api.github.com/search/commits?q=repo:$REPO+$KEYWORD&per_page=$PER_PAGE&page=$PAGE&sort=committer-date&order=desc" \
              -H "Accept: application/vnd.github.v3+json")

            if [[ $(echo "$RESPONSE" | jq -r '.message') != "null" ]]; then
              echo -e "\033[31mAPI请求失败，返回内容：$RESPONSE\033[0m"
              # 删除克隆的仓库目录
              echo -e "\033[31m由于错误，正在删除克隆的仓库目录 $REPO_DIR\033[0m"
              rm -rf "$REPO_DIR"
              exit 1
            fi
  
            # 提取提交的 SHA 列表
            PAGE_COMMIT_LIST=$(echo "$RESPONSE" | jq -r '.items[].sha')
  
            # 如果没有返回任何提交，退出循环
            if [ -z "$PAGE_COMMIT_LIST" ]; then
              break
            fi
  
            # 将当前页的提交加入该仓库的提交列表
            REPO_COMMIT_LIST="$REPO_COMMIT_LIST $PAGE_COMMIT_LIST"
            echo -e "\033[33m搜索到仓库 '$REPO' 的提交: \n$PAGE_COMMIT_LIST\033[0m"
            # 继续获取下一页
            ((PAGE++))
          done

          # 从文件读取已处理的提交
          if [ -f "$PROCESSED_COMMITS_FILE" ]; then
            PROCESSED_COMMITS=$(cat "$PROCESSED_COMMITS_FILE")
          else
            PROCESSED_COMMITS=""
          fi

          # 如果没有已处理的提交，则跳过过滤
          if [ -z "$PROCESSED_COMMITS" ]; then
            echo -e "\033[33m没有已处理的提交，跳过过滤。\033[0m"
          else

            # 从 URL 提取 commit ID，并将其作为已处理的提交
            PROCESSED_COMMIT_IDS=$(echo "$PROCESSED_COMMITS" | sed -E 's#.*/commit/([a-f0-9]+)#\1#')
            echo -e "\033[33m已处理的提交：\n$PROCESSED_COMMIT_IDS\033[0m"
            
            # 去除多余空格和换行符
            REPO_COMMIT_LIST=$(echo "$REPO_COMMIT_LIST" | tr -s '[:space:]' '\n' | sed '/^$/d')
            PROCESSED_COMMIT_IDS=$(echo "$PROCESSED_COMMIT_IDS" | tr -s '[:space:]' '\n' | sed '/^$/d')
            
            # 过滤 REPO_COMMIT_LIST，移除已处理的提交
            REPO_COMMIT_LIST=$(echo "$REPO_COMMIT_LIST" | grep -v -F -f <(echo "$PROCESSED_COMMIT_IDS") | tr '\n' ' ')
          
            # 打印过滤后剩下的待处理提交
            echo -e "\033[33m过滤后的待处理提交：\n$REPO_COMMIT_LIST\033[0m"
          
            # 打印跳过的提交：已处理的提交列表与待处理提交列表的交集
            SKIPPED_COMMITS=$(echo "$REPO_COMMIT_LIST" | tr ' ' '\n' | grep -F -f <(echo "$PROCESSED_COMMIT_IDS") | tr '\n' ' ')
            
            if [ -n "$SKIPPED_COMMITS" ]; then
              echo -e "\033[31m跳过的提交：\n$SKIPPED_COMMITS\033[0m"
            else
              echo -e "\033[32m没有提交被跳过。\033[0m"
            fi
          fi


          # 如果该仓库没有符合条件的提交，跳过该仓库
          if [ -z "$REPO_COMMIT_LIST" ]; then
            echo -e "\033[33m仓库 '$REPO' 没有找到包含 '$KEYWORD' 的提交，跳过该仓库。\033[0m"
            rm -rf "$REPO_DIR"
            continue
          fi

          # 处理每个提交，获取变更文件并提取目录
          for COMMIT_SHA in $REPO_COMMIT_LIST; do
            echo -e "\033[36m正在处理提交:\n$COMMIT_SHA...\033[0m"
                        
            # 获取该提交的详细信息
            # COMMIT_FILES=$(curl -s -H "Authorization: token $GITHUB_TOKEN" "https://api.github.com/repos/$REPO/commits/$COMMIT_SHA")
            COMMIT_FILES=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
              "https://api.github.com/repos/$REPO/commits/$COMMIT_SHA")

            if [[ $(echo "$COMMIT_FILES" | jq -r '.message') != "null" ]]; then
              echo -e "\033[31mAPI请求失败，返回内容：$COMMIT_FILES\033[0m"
              exit 1
            fi

            # 检查返回的数据是否包含有效的文件变更
            FILES=$(echo "$COMMIT_FILES" | jq -r '.files | if . != null then .[].filename else empty end')
            echo -e "\033[36m当前提交内文件：\n$FILES\033[0m"

            if [ -z "$FILES" ]; then
              echo -e "\033[31m提交 $COMMIT_SHA 没有修改文件，跳过。\033[0m"
              continue
            fi

            COMMIT_URL=$(echo "$COMMIT_FILES" | jq -r '.html_url // "No URL available"')  # 处理 null
            COMMIT_URLS="$COMMIT_URLS $COMMIT_URL"
            echo -e "\033[36m查看更多信息：\n$COMMIT_URL\033[0m"
  
            # 动态分组
            declare -A groups  # 初始化分组数组
            DEPTH=3  # 默认深度
            max_depth=0

            for FILE in $FILES; do
              # echo "处理文件: $FILE"
              DIR=$(dirname "$FILE")  # 提取文件的目录部分
              # echo "文件目录: $DIR"
              # 计算文件路径中斜杠的数量，作为深度的基础
              file_depth=$(echo "$DIR" | tr -cd '/' | wc -c)
              # 输出当前文件的目录和计算出的基础深度
              # echo "文件目录: '$DIR', 文件深度计算前斜杠数: $file_depth"
              # 斜杠数量加一，以得到更准确的目录层级深度
              file_depth=$((file_depth == 0 ? 1 : file_depth + 1))
              # 输出最终确定的文件深度
              # echo "文件深度: $file_depth"              
              max_depth=$(($max_depth > $file_depth ? $max_depth : $file_depth))
              # echo "当前最大深度: $max_depth"
              prefix=$(echo "$DIR" | cut -d/ -f1-$DEPTH)
              # echo "当前前缀: $prefix"
              groups["$prefix"]+="$DIR "
              # echo "目录加入分组: ${groups[$prefix]}"
            done
            # 根据最大文件路径深度调整分组深度
            if [ $max_depth -eq $DEPTH ]; then
              DEPTH=$((DEPTH-1))  # 减少一层分组深度
              echo -e "\033[35m分组深度调整为 $DEPTH，重新分组完成。\033[0m"
              unset groups
              declare -A groups
              for FILE in $FILES; do
                DIR=$(dirname "$FILE")
                prefix=$(echo "$DIR" | cut -d/ -f1-$DEPTH)
                groups["$prefix"]+="$DIR "
              done
            fi

            # 分组处理
            for prefix in "${!groups[@]}"; do
              echo -e "\033[32m处理组:$prefix\033[0m"
              # 将组内的路径读取到一个数组中
              read -a paths <<< "${groups[$prefix]}"
              # 设置初始公共路径为数组的第一个元素
              common_path=${paths[0]}
              # 比较组内所有路径，更新公共路径
              for path in "${paths[@]}"; do
                # 重置用于存储公共部分的数组
                COMMON_DIR_ARRAY=()
                # 分割当前公共路径和下一个路径
                IFS="/" read -r -a DIR1_PARTS <<< "$common_path"
                IFS="/" read -r -a DIR2_PARTS <<< "$path"
                # 比较每个部分
                for ((i = 0; i < ${#DIR1_PARTS[@]} && i < ${#DIR2_PARTS[@]}; i++)); do
                  if [ "${DIR1_PARTS[$i]}" == "${DIR2_PARTS[$i]}" ]; then
                    COMMON_DIR_ARRAY+=("${DIR1_PARTS[$i]}")
                  else
                    break
                  fi
                done
                common_path=$(IFS="/"; echo "${COMMON_DIR_ARRAY[*]}")
              done
              echo -e "\033[32m处理组: $prefix 的公共目录路径：$common_path\033[0m"
              REPO_RESULTS+=("$common_path")  # 存储最长公共路径
            done
            unset groups  # 清理分组数据
          done

          # 去重并排序目录列表
          REPO_RESULTS=($(printf '%s\n' "${REPO_RESULTS[@]}" | sort -u))
  
          echo -e "\033[32m仓库 '$REPO' 修改过的目录：\033[0m"
          for DIR in "${REPO_RESULTS[@]}"; do
            echo "$REPO_DIR/$DIR"
          done
          echo -e "\033[32m$REPO 所有目录统计完成。\033[0m"

          # 创建目标目录并移动文件
          TARGET_DIR="./$REPO"
          mkdir -p "$TARGET_DIR"

          # 检查文件是否存在
          if [ -f "$DIRECTORY_FILE" ]; then
            # 如果文件存在，从 DIRECTORY_FILE 读取现有的行到数组中
            mapfile -t directory_lines < "$DIRECTORY_FILE"
          else
            # 如果文件不存在，初始化一个空数组
            directory_lines=()
          fi

          # 使用关联数组避免重复添加目录
          declare -A directory_map
          for dir in "${directory_lines[@]}"; do
              directory_map["$dir"]=1  # 标记已存在的目录
              echo "Existing directory added to map: $dir"
          done
          # 更新 DIRECTORY_FILE 并更新目录映射
          for repo in "${REPO_RESULTS[@]}"; do
            if [[ ! ${directory_map["$repo"]} ]]; then
              echo "Adding new directory: $repo"
              echo "$repo"
              directory_map["$repo"]=1  # 标记新目录
            else
              echo "Directory already exists, skipping: $repo"
            fi
          done | sort -u >> "$DIRECTORY_FILE"

          # 输出关联数组的最终状态
          echo "Final state of directory map:"
          for k in "${!directory_map[@]}"; do
            echo "Key: $k"
          done

          # 将处理过的提交链接一次性写入 processed_commits.txt
          # printf "%s\n" $REPO_COMMIT_LIST >> "$PROCESSED_COMMITS_FILE"
          printf "%s\n" $COMMIT_URLS >> "$PROCESSED_COMMITS_FILE"

          # 使用关联数组的键创建一个更新后的目录列表
          updated_directory_lines=("${!directory_map[@]}")
	  echo "Updated directory lines: ${updated_directory_lines[@]}"
          # 移动目录
          #for DIR in "${REPO_RESULTS[@]}"; do
          for DIR in "${updated_directory_lines[@]}"; do	  
            TARGET_SUB_DIR="$TARGET_DIR/$DIR"
            mkdir -p "$TARGET_SUB_DIR"
  
            if [ -d "$REPO_DIR/$DIR" ]; then
              echo -e "\033[32m移动目录 $REPO_DIR/$DIR 中的文件...\033[0m"
              mv "$REPO_DIR/$DIR"/* "$TARGET_SUB_DIR" 2>/dev/null || true
            else
              echo -e "\033[31m目录 $REPO_DIR/$DIR 在仓库中不存在或者已经移动过，跳过此目录。\033[0m"
            fi
          done

          # 删除仓库目录
          rm -rf "$REPO_DIR"
          echo -e "\033[32m删除仓库临时目录 $REPO_DIR。\033[0m"
        done
        echo -e "\033[32m所有仓库的目录统计完成。\033[0m"

    # 提交更新
    - name: Commit Changes
      run: |
        if [[ -n $(git status -s) ]]; then
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git commit -m "Auto Update $(TZ='Asia/Shanghai' date +'%Y-%m-%d %H:%M:%S')"
          git push origin main          
          echo -e "\033[32m提交更改并推送到仓库。\033[0m"
        else
          echo -e "\033[33m没有更改需要提交。\033[0m"
        fi
          
    # 清理工作流
    - name: Cleanup Workflow
      uses: Mattraks/delete-workflow-runs@main
      with:
        retain_days: 0
        keep_minimum_runs: 2
        delete_workflow_pattern : Sync OpenWrt fix
